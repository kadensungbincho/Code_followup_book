{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Celery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celery is another queue management system. In contrast RQ, it is broker agnostric and can use various software as broker, such as Redis, RbiitMQ or Amazon SQS. Moreover if you are brave enough, it is possible to write your own driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celery also needs a backend for storing the results of the job. It supports a bunch of solution, such as Redis, MongoDB, SQL databases, ElasticSearch, files, etc. Just like for brokers, you can also write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celery implements its own serialization format for its jobs. However, this format is not specifid to Python. That means it is possible to implement job creators or consumers in different languages; there are already clients in PHP and Javascript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Celery, tasks are functions that can be called asynchronously. When called, Celery puts them in the broker queue for execution. Remote workers then execute the tasks, putting the task results into the backend.\n",
    "When called, a task returns a celery.result.AsyncResult object. This object offers a principal method, get, which returns that result as soon as it is available, blocking the program in the meantime.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import celery\n",
    "\n",
    "app = celery.Celery('celery-task', \n",
    "                   broker='redis://localhost',\n",
    "                   backend='redis://localhost')\n",
    "\n",
    "@app.task\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result =add.delay(4, 4)\n",
    "    print(\"Task state: %s\" % result.state)\n",
    "    print(\"Result: %s\" % result.get())\n",
    "    print(\"Task state: %s\" % result.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "celery task. The celery application is created with the main module name as its first argument, and the th URL to access the broker and backends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app.task function decorator registers the add task so it can be used asynchronously in the application, leveragin Celery workers for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once run, this program prints the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The celery command line tool provides a broad set of commands to manipulate and inspect the jobs queue and the workers. It is in charge of starting the actual workers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Handling Failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task executions might fail, and in this case it is crucial to handle that properly. It is common for tasks to depend on external services, such as a remote database or a REST API. Connection failure might be transient; it is therefore better to deal with defeat and retry later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
